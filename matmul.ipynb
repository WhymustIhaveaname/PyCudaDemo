{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c816e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd8da80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double a 32x32 matrix using 32x32 threads\n",
      "execute 0: 261.545 us\n",
      "execute 1: 19.312 us\n",
      "execute 2: 11.921 us\n",
      "execute 3: 21.696 us\n",
      "execute 4: 9.775 us\n",
      "the answer:\n",
      " [[2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " ...\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"double a 32x32 matrix using 32x32 threads\")\n",
    "mod = SourceModule(\"\"\"\n",
    "    __global__ void doublify(float *a){\n",
    "        int idx = threadIdx.x + threadIdx.y*blockDim.x;\n",
    "        a[idx]*=2;\n",
    "    }\n",
    "\"\"\")\n",
    "func=mod.get_function(\"doublify\")\n",
    "\n",
    "a=numpy.ones((32,32),dtype=numpy.float32)\n",
    "a_gpu=cuda.mem_alloc(a.nbytes)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    cuda.memcpy_htod(a_gpu,a)\n",
    "    tik=time.time()\n",
    "    func(a_gpu,block=(32,32,1))\n",
    "    tok=time.time()\n",
    "    print(\"execute %d: %.3f us\"%(i,(tok-tik)*1e6))\n",
    "\n",
    "a_doubled=numpy.empty_like(a)\n",
    "cuda.memcpy_dtoh(a_doubled,a_gpu)\n",
    "print(\"the answer:\\n\",a_doubled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a9067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double a 32x32 matrix using 32 threads\n",
      "execute 0: 43.392 us\n",
      "execute 1: 25.988 us\n",
      "execute 2: 17.166 us\n",
      "execute 3: 15.497 us\n",
      "execute 4: 15.020 us\n",
      "the answer:\n",
      " [[2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " ...\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"double a 32x32 matrix using 32 threads\")\n",
    "mod = SourceModule(\"\"\"\n",
    "    __global__ void doublify(float *a,int D2){\n",
    "        for(int i=threadIdx.x*D2;i<threadIdx.x*D2+D2;i++){\n",
    "            a[i]*=2;\n",
    "        }\n",
    "    }\n",
    "\"\"\")\n",
    "func=mod.get_function(\"doublify\")\n",
    "\n",
    "a=numpy.ones((32,32),dtype=numpy.float32)\n",
    "a_gpu=cuda.mem_alloc(a.nbytes)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    cuda.memcpy_htod(a_gpu,a)\n",
    "    tik=time.time()\n",
    "    func(a_gpu,numpy.int32(32),block=(32,1,1))\n",
    "    tok=time.time()\n",
    "    print(\"execute %d: %.3f us\"%(i,(tok-tik)*1e6))\n",
    "\n",
    "a_doubled=numpy.empty_like(a)\n",
    "cuda.memcpy_dtoh(a_doubled,a_gpu)\n",
    "print(\"the answer:\\n\",a_doubled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4fe10f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix ptoduct between a 1024x1024 matrix and a 1024 vector using 1024 threads\n",
      "                 cuda,      numpy\n",
      "execute 0:  42.915 us, 2017.498 us\n",
      "execute 1:  61.274 us, 458.241 us\n",
      "execute 2:  60.320 us, 104.427 us\n",
      "execute 3:  56.028 us, 101.566 us\n",
      "execute 4:  54.598 us, 102.043 us\n",
      "the answer:\n",
      " [1024. 1024. 1024. ... 1024. 1024. 1024.]\n"
     ]
    }
   ],
   "source": [
    "print(\"matrix ptoduct between a 1024x1024 matrix and a 1024 vector using 1024 threads\")\n",
    "mod = SourceModule(\"\"\"\n",
    "    __global__ void doublify(float *k,float *x,float *b,int D2){\n",
    "        b[threadIdx.x]=0;\n",
    "        for(int i=0;i<D2;i++){\n",
    "            b[threadIdx.x]+=k[threadIdx.x*D2+i]*x[i];\n",
    "        }\n",
    "    }\n",
    "\"\"\")\n",
    "func=mod.get_function(\"doublify\")\n",
    "\n",
    "k=numpy.ones((1024,1024),dtype=numpy.float32)\n",
    "x=numpy.ones(1024,dtype=numpy.float32)\n",
    "k_gpu=cuda.mem_alloc(k.nbytes)\n",
    "x_gpu=cuda.mem_alloc(x.nbytes)\n",
    "b_gpu=cuda.mem_alloc(x.nbytes)\n",
    "\n",
    "print(\"                 cuda,      numpy\")\n",
    "for i in range(5):\n",
    "    cuda.memcpy_htod(k_gpu,k)\n",
    "    cuda.memcpy_htod(x_gpu,x)\n",
    "    tik=time.time()\n",
    "    func(k_gpu,x_gpu,b_gpu,numpy.int32(1024),block=(1024,1,1))\n",
    "    tok=time.time()\n",
    "    numpy.matmul(k,x)\n",
    "    tok2=time.time()\n",
    "    print(\"execute %d: %7.3f us, %7.3f us\"%(i,(tok-tik)*1e6,(tok2-tok)*2e6))\n",
    "\n",
    "b=numpy.empty_like(x)\n",
    "cuda.memcpy_dtoh(b,b_gpu)\n",
    "print(\"the answer:\\n\",b)\n",
    "assert numpy.sum(numpy.abs(b-numpy.matmul(k,x)))==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a68dba17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix ptoduct between a 1048576x1024 matrix and a 1024 vector\n",
      "using 1024 threads and 1024 blocks\n",
      "                 cuda,      numpy\n",
      "execute 0:  48.161 us, 123885.632 us\n",
      "execute 1:  47.684 us, 117093.086 us\n",
      "execute 2:  55.075 us, 123652.935 us\n",
      "execute 3:  47.684 us, 117362.499 us\n",
      "execute 4:  49.591 us, 116419.315 us\n",
      "the answer:\n",
      " [1024. 1024. 1024. ... 1024. 1024. 1024.]\n"
     ]
    }
   ],
   "source": [
    "blockdimx=1024\n",
    "print(\"\"\"matrix ptoduct between a %dx1024 matrix and a 1024 vector\n",
    "using 1024 threads and %d blocks\"\"\"%(1024*blockdimx,blockdimx))\n",
    "\n",
    "mod = SourceModule(\"\"\"\n",
    "    __global__ void doublify(float *k,float *x,float *b,int D2){\n",
    "        int idx=blockIdx.x*blockDim.x+threadIdx.x;\n",
    "        for(int i=0;i<D2;i++){\n",
    "            b[idx]+=k[idx*D2+i]*x[i];\n",
    "        }\n",
    "    }\n",
    "\"\"\")\n",
    "func=mod.get_function(\"doublify\")\n",
    "\n",
    "\n",
    "k=numpy.ones((1024*blockdimx,1024),dtype=numpy.float32)\n",
    "x=numpy.ones(1024,dtype=numpy.float32)\n",
    "k_gpu=cuda.mem_alloc(k.nbytes)\n",
    "x_gpu=cuda.mem_alloc(x.nbytes)\n",
    "b_gpu=cuda.mem_alloc(4*1024*blockdimx)\n",
    "\n",
    "print(\"                 cuda,      numpy\")\n",
    "for i in range(5):\n",
    "    cuda.memcpy_htod(k_gpu,k)\n",
    "    cuda.memcpy_htod(x_gpu,x)\n",
    "    cuda.memset_d32(b_gpu,0,1024*blockdimx)\n",
    "    tik=time.time()\n",
    "    func(k_gpu,x_gpu,b_gpu,numpy.int32(1024),block=(1024,1,1),grid=(blockdimx,1))\n",
    "    tok=time.time()\n",
    "    numpy.matmul(k,x)\n",
    "    tok2=time.time()\n",
    "    print(\"execute %d: %7.3f us, %7.3f us\"%(i,(tok-tik)*1e6,(tok2-tok)*2e6))\n",
    "\n",
    "b=numpy.empty(1024*blockdimx,dtype=numpy.float32)\n",
    "cuda.memcpy_dtoh(b,b_gpu)\n",
    "print(\"the answer:\\n\",b)\n",
    "assert numpy.sum(numpy.abs(b-numpy.matmul(k,x)))==0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
